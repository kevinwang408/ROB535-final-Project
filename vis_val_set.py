import os
import json
import torch
import mmcv
from mmdet.apis import init_detector, inference_detector
from mmdet.registry import VISUALIZERS
from tqdm import tqdm

# ================= è¨­å®šå€ (è«‹ä¿®æ”¹é€™è£¡) =================
# for kitti val set visualization
# 1. Config æª”æ¡ˆ
config_file = 'kitti_config.py'

# 2. æ¬Šé‡æª”
checkpoint_file = 'work_dirs/deformable_detr_kitti/epoch_50.pth'

# 3. é©—è­‰é›†çš„ JSON åå–® (ç¨‹å¼æœƒå¾é€™è£¡çŸ¥é“è©²è·‘å“ªå¹¾å¼µåœ–)
val_json_file = 'data/kitti/annotations/kitti_val.json'

# 4. åœ–ç‰‡æ‰€åœ¨çš„çœŸå¯¦è³‡æ–™å¤¾ (KITTI çš„è©±ï¼Œé©—è­‰åœ–å…¶å¯¦æ··åœ¨ train è³‡æ–™å¤¾è£¡)
img_root = 'D:/ROB 535 HW/detr_facebook/mmdetection/data/kitti/images/train'

# 5. è¼¸å‡ºçµæœå­˜åˆ°å“ª
output_folder = 'vis_results_kitti'

# 6. ä¿¡å¿ƒé–€æª»
score_thr = 0.3
# =======================================================

def main():
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸš€ ä½¿ç”¨è£ç½®: {device}")
    
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # 1. è®€å– JSON åå–®
    print(f"ğŸ“– æ­£åœ¨è®€å–åå–®: {val_json_file}...")
    with open(val_json_file, 'r') as f:
        coco_data = json.load(f)
    
    # æå–æ‰€æœ‰é©—è­‰é›†åœ–ç‰‡çš„æª”å
    # COCO JSON çµæ§‹: data['images'] æ˜¯ä¸€å€‹ listï¼Œè£¡é¢æœ‰ {'file_name': 'xxx.png', ...}
    target_images = [img_info['file_name'] for img_info in coco_data['images']]
    
    print(f"âœ… åå–®è®€å–å®Œç•¢ï¼Œå…±æœ‰ {len(target_images)} å¼µé©—è­‰åœ–ç‰‡ã€‚")

    # 2. è¼‰å…¥æ¨¡å‹
    try:
        model = init_detector(config_file, checkpoint_file, device=device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return

    visualizer = VISUALIZERS.build(model.cfg.visualizer)
    visualizer.dataset_meta = model.dataset_meta

    # 3. é–‹å§‹æ¨è«– (ç‚ºäº†ç¯€çœæ™‚é–“ï¼Œæˆ‘å€‘åªè·‘å‰ 50 å¼µï¼Œæƒ³è·‘å…¨éƒ¨è«‹æ‹¿æ‰ [:50])
    print("ğŸ¨ é–‹å§‹ç¹ªè£½åœ–ç‰‡...")
    for i, file_name in enumerate(tqdm(target_images[:50])):
        
        # çµ„åˆå®Œæ•´è·¯å¾‘
        img_path = os.path.join(img_root, file_name)
        
        # æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å­˜åœ¨
        if not os.path.exists(img_path):
            print(f"âš ï¸ æ‰¾ä¸åˆ°åœ–ç‰‡: {img_path}ï¼Œè·³éã€‚")
            continue

        # æ¨è«–
        result = inference_detector(model, img_path)
        
        # è®€åœ–
        img = mmcv.imread(img_path)
        img = mmcv.imconvert(img, 'bgr', 'rgb')

        # ç¹ªåœ–
        visualizer.add_datasample(
            name=file_name,
            image=img,
            data_sample=result,
            draw_gt=False, # å¦‚æœè¨­ç‚º Trueï¼Œå®ƒæœƒæŠŠæ¨™æº–ç­”æ¡ˆ(ç¶ æ¡†)ä¹Ÿç•«ä¸Šå»ï¼Œæ–¹ä¾¿å°æ¯”ï¼
            show=False,
            pred_score_thr=score_thr
        )
        
        # å­˜æª”
        out_file_path = os.path.join(output_folder, file_name)
        res_img = visualizer.get_image()
        res_img = mmcv.imconvert(res_img, 'rgb', 'bgr')
        mmcv.imwrite(res_img, out_file_path)

    print(f"âœ… å…¨éƒ¨å®Œæˆï¼çµæœå·²å„²å­˜è‡³: {output_folder}")

if __name__ == '__main__':
    main()